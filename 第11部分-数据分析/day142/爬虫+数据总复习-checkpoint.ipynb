{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一章爬虫介绍\n",
    "- 爬虫的分类:聚焦,通用,增量式\n",
    "- robots协议\n",
    "- 反爬机制:\n",
    "- 反反爬策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二章http和https协议\n",
    "- 协议概念;client和server进行数据交互的形式\n",
    "- 常用请求头信息:User_Agent , Connection\n",
    "- 常用响应头信息:Content_Type\n",
    "- 三种加密方式:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三章 requests模块\n",
    "- 请求数据方式（两个方法+四种方式）\n",
    "- UA伪装（反反爬策略）\n",
    "- 爬取基于ajax请求数据的流程\n",
    "    - 使用抓包工具获取请求的url\n",
    "    - 对url发请求,获取页面数据\n",
    "    - 持久化存储\n",
    "- 爬取图片数据的方式\n",
    "    - IO\n",
    "    - urllib\n",
    "- 实现模拟登陆\n",
    "    - \n",
    "- 处理cookie（反反爬策略）\n",
    "    - 手动处理\n",
    "    - 自动处理\n",
    "- 设置代理（反反爬策略）\n",
    "    - proxies字典 {'http':'ip+port'}\n",
    "- 使用线程池（multiprocessing.dummy.Pool）实现数据爬取\n",
    "    - map(func,list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四章 数据解析\n",
    "- 正则解析\n",
    "- xpath解析\n",
    "    - xpath插件\n",
    "    - 数据加密-煎蛋网（反反爬策略）\n",
    "    - 爬取全国所有城市名称（xpath表达式的特殊使用）\n",
    "    - 常见错误处理：HTTPConnectionPool（host:XX）Max retries exceeded with url\n",
    "- bs4解析\n",
    "    - soup.select(\"a  .xxx  div\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第五章 验证码处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第六章 动态数据加载\n",
    "    - selenium\n",
    "    - phantomjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第七章 移动端数据爬取\n",
    "    - localhost:8888\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第八章 scrapy框架基础+持久化存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第九章 递归解析和post请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十章 日志等级和请求传参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十一章 UA池和代理池"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十二章 scrapy中selenium的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十三章 全站数据爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十四章 分布式爬虫\n",
    "    1.导包  from scrapy_redis.spiders import RedisCrawlSpider\n",
    "    2.修改爬虫文件: 父类,allow_demains和start_urls删除,redis_key\n",
    "    3.爬取数据的程序\n",
    "    4.在配置文件中使用scrapy_redis模块中的管道和调度器\n",
    "    5.在配置文件中进行数据库的ip,port的配置\n",
    "    6.redis数据库中进行配置\n",
    "    7.开启redis\n",
    "    8.执行爬虫文件  scrapy runspider  xxx.py\n",
    "    9.给调度器中仍入一个url: lpush xxx www.xxx.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十五章 增量式爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分析\n",
    "- numpy\n",
    "    - 切片\n",
    "    - 变形\n",
    "    - 级联\n",
    "    - 切分\n",
    "    - 广播机制\n",
    "    - 排序\n",
    "- Series\n",
    "    - 过滤空值\n",
    "    - 去重\n",
    "- DataFrame\n",
    "    - 创建\n",
    "    - 索引\n",
    "        - 取列：df['col'] df.col\n",
    "        - 取行：df.loc[index]\n",
    "        - 取元素：df.loc[index,col]\n",
    "    - 切片：\n",
    "        - 切列：df.loc[:,x:x]\n",
    "        - 切行：df[x:x]\n",
    "    - 空值检测和过滤\n",
    "        - 空值检测函数：isnull() notnull() any() all()\n",
    "        - 空值过滤思路：isnull()_>any()\n",
    "        - 空值过滤函数：df.dropna()\n",
    "        - 检测重复行：\n",
    "        - 过滤重复行：drop_duplicates()\n",
    "        - 随机取样：take()\n",
    "        - 级联机制：concat(join=)\n",
    "        - 合并机制：merge()\n",
    "        - 替换：replace(to_replace,value)\n",
    "        - 映射：map(dic) map(func)\n",
    "        - 分组：groupby\n",
    "        - 分组聚合：mean(),sum(), apply(func)   transform(func)\n",
    "        - 条件查询函数：query()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
